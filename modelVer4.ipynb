{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tokenizer import NLTKTokenizer\n",
    "\n",
    "CWD = os.getcwd()\n",
    "TRAIN_DATA_PATH = os.path.join(CWD, 'data', 'trainset.csv')\n",
    "VALID_DATA_PATH = os.path.join(CWD, 'data', 'validset.csv')\n",
    "TEST_DATA_PATH = os.path.join(CWD, 'data', 'testset.csv')\n",
    "DICT_PATH = os.path.join(CWD, 'data', 'dictionary.pkl')\n",
    "WORKERS = os.cpu_count() // 2\n",
    "Tokenizer = NLTKTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitSent(doc):\n",
    "    return doc.split('$$$')\n",
    "\n",
    "\n",
    "def GenDict(train, valid):\n",
    "    global Tokenizer\n",
    "    if os.path.exists(DICT_PATH):\n",
    "        Tokenizer = NLTKTokenizer.load_from_file(DICT_PATH)\n",
    "    else:\n",
    "        for item in train['Abstract']:\n",
    "            Tokenizer.build_dict(item)\n",
    "\n",
    "        for item in valid['Abstract']:\n",
    "            Tokenizer.build_dict(item)\n",
    "\n",
    "        Tokenizer.save_to_file(DICT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_DATA_PATH)\n",
    "valid = pd.read_csv(VALID_DATA_PATH)\n",
    "test = pd.read_csv(TEST_DATA_PATH)\n",
    "\n",
    "train['Abstract'] = train['Abstract'].apply(func=SplitSent)\n",
    "valid['Abstract'] = valid['Abstract'].apply(func=SplitSent)\n",
    "GenDict(train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Abstract'] = test['Abstract'].apply(func=SplitSent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_onehot(labels):\n",
    "    '''\n",
    "    Convert labels to one-hot encoding\n",
    "\n",
    "    Args : \n",
    "        labels:( DataFrame column item ) \n",
    "    Return :\n",
    "        one_hot_labels: ( DataFrame column item )\n",
    "    '''\n",
    "    one_hot_labels = []\n",
    "    label_list = labels.split(' ')\n",
    "    label_dict = {'BACKGROUND': 0, 'OBJECTIVES':1, 'METHODS':2, 'RESULTS':3, 'CONCLUSIONS':4, 'OTHERS':5}\n",
    "    for label in label_list:\n",
    "        onehot = [0,0,0,0,0,0]\n",
    "        for l in label.split('/'):\n",
    "            onehot[label_dict[l]] = 1\n",
    "        one_hot_labels.append(onehot)\n",
    "    \n",
    "    return one_hot_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(dataset):\n",
    "    '''\n",
    "    encode 'Abstract' and convert label to one_hot\n",
    "\n",
    "\n",
    "    Args:\n",
    "        dataset(pd.DataFrame)\n",
    "    '''\n",
    "    global Tokenizer\n",
    "    dataset['Abstract'] = dataset['Abstract'].apply(func=Tokenizer.encode)\n",
    "    if 'Task 1' in dataset.columns:\n",
    "        dataset['Task 1'] = dataset['Task 1'].apply(func=labels_to_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_data(train)\n",
    "encode_data(valid)\n",
    "encode_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                                                     D05945\n",
       "Abstract    [[31341, 37103, 33906, 21235, 37219, 37059, 37...\n",
       "Task 1      [[1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0], [1, 1...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Abstract(Dataset):\n",
    "    def __init__(self, data, pad_idx, eos_token):\n",
    "        self.data = data\n",
    "        self.pad_idx = pad_idx\n",
    "        self.eos_token = eos_token\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data.index)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data.iloc[index]\n",
    "    \n",
    "    def collate_fn(self, datas):\n",
    "        abstracts = [torch.as_tensor(abstract, dtype=torch.long)for data in datas for abstract in data['Abstract']]\n",
    "        batch_abstracts = pad_sequence(\n",
    "            abstracts, batch_first=True, padding_value=self.pad_idx)\n",
    "        \n",
    "        b, s = batch_abstracts.size() # b: batch, s:sequence length\n",
    "        batch_eos = batch_abstracts == 3\n",
    "        eos_index_matrix = batch_eos.nonzero()\n",
    "        eos_index_list = list()\n",
    "        prev = 0\n",
    "        for row in eos_index_matrix:\n",
    "            eos_index_list.append(row[1].item()+prev)\n",
    "            prev = prev + s \n",
    "            \n",
    "        batch_labels = None\n",
    "        labels = [\n",
    "            label for data in datas if 'Task 1' in data for label in data['Task 1']]\n",
    "        if len(labels) != 0:\n",
    "            batch_labels = torch.as_tensor(labels, dtype=torch.float)\n",
    "            batch_labels = batch_labels.view(-1, 6)\n",
    "\n",
    "        return batch_abstracts, batch_labels, torch.as_tensor(eos_index_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                                                     T00001\n",
       "Abstract    [[37010, 36576, 37189, 36992, 36376, 37138, 37...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = Abstract(data=test, pad_idx=0, eos_token=3)\n",
    "testset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset=testset, batch_size = 2, collate_fn=testset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[37010, 36576, 37189, 36992, 36376, 37138, 37180, 36781, 36687, 37177,\n",
      "         36959, 37010, 37087, 37000, 36948, 36709, 37108, 37188,     3,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [37139, 37093, 36994, 37010, 36576, 37197, 37180, 36575, 30989, 37010,\n",
      "         37132, 37138, 36366, 37180, 37119, 37180, 35771, 37138, 12805, 37180,\n",
      "         22502, 36768, 37226, 37138, 37177, 37180, 36565, 36510, 37188,     3],\n",
      "        [37125, 37180, 37203, 37056, 36848, 25172,     4, 37132, 25448, 37138,\n",
      "         37180, 29488, 36877,     4, 37132, 37184, 37138, 36069, 37001, 37123,\n",
      "         25448, 37006, 37188,     3,     0,     0,     0,     0,     0,     0],\n",
      "        [37227, 37228, 37180, 37178, 37230,     4, 36552, 37194,     4, 37196,\n",
      "         37214, 37010, 36576, 37197, 37180, 37164,     4, 37181, 35861,     4,\n",
      "         37074, 33042, 37132, 37226, 37177, 37188,     3,     0,     0,     0],\n",
      "        [27399, 37063, 37157, 37180, 37230, 37153, 37160, 37188,     3,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [37205, 37240, 37214, 37188, 37184, 37253, 24567, 28725, 37225, 37188,\n",
      "             3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [37187, 37218, 37232, 37214, 37132, 37148, 37217, 36983, 37138, 37221,\n",
      "             4, 37137,  9684, 37113, 37180, 37124, 37081, 37074, 37180, 36787,\n",
      "             4, 37188,     3,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [35767, 37086, 36651, 37086, 37234, 37227, 37097, 37194, 37180, 36851,\n",
      "             4, 36651, 37180, 37192, 37181,  6377, 37119, 37086, 36651, 37188,\n",
      "             3,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [37242, 37204, 37203, 36801, 36999, 36946, 37086, 37234, 37202, 37134,\n",
      "         36985, 37188,     3,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [37189, 35767, 37151, 33281, 37219, 37188,     3,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [37182, 37220, 36599, 37216,     4, 35767, 37234, 37151, 37086, 37234,\n",
      "         35802, 37041, 26758, 37145, 37188,     3,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [37139, 37100, 35767, 35802, 37213, 37180, 37173, 36868, 37180, 37139,\n",
      "         37180, 36916, 37180, 37098, 37180,     4, 35737, 37108, 37188,     3,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "None\n",
      "tensor([ 18,  59,  83, 116, 128, 160, 202, 230, 252, 276, 315, 349])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index out of range: Tried to access index 18 out of table with 11 rows. at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:418",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a0fcac1aef8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index out of range: Tried to access index 18 out of table with 11 rows. at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:418"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for x, y, z in test_loader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(z)\n",
    "    print(torch.index_select(x, 0, z))\n",
    "    i += 1\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Abstract    [[42485, 35732, 42367, 42450, 38674, 10, 42508...\n",
       "Task 1      [[1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0], [1, 1...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8134, -0.9588,  0.0026,  0.2593,  0.3925],\n",
       "        [-0.4434,  1.2400, -1.2114,  0.6910,  0.0485],\n",
       "        [ 0.0859, -0.4183,  0.7825, -0.2081, -0.1877]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3,5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "m, n = a.size()\n",
    "print(m)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52021"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tokenizer.vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42255,\n",
       " 41744,\n",
       " 42473,\n",
       " 42225,\n",
       " 41498,\n",
       " 42402,\n",
       " 42451,\n",
       " 41975,\n",
       " 41872,\n",
       " 42453,\n",
       " 42195,\n",
       " 42255,\n",
       " 42396,\n",
       " 42237,\n",
       " 42170,\n",
       " 41899,\n",
       " 42372,\n",
       " 42465,\n",
       " 3]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[0]['Abstract'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ torch.as_tensor(abstract, dtype=torch.float) for abstract in dataset[0]['Task 1'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 1., 0., 0.])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_labels = pad_sequence( labels, batch_first=True )\n",
    "batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = [ torch.as_tensor(vec) for  vec in dataset[0]['Abstract'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([42485, 35732, 42367, 42450, 38674,    10, 42508, 42313, 42472, 38387,\n",
       "         42474, 42459, 42455, 42471, 42228, 42500, 42356, 42451, 42463, 42441,\n",
       "         42463, 42416, 42306, 42468, 42437, 42396, 42445, 42526, 42450, 42105,\n",
       "         42115, 42451, 42550, 42366, 42465,     3]),\n",
       " tensor([42007, 42500, 42497, 42204, 42502, 42035, 42438, 42453, 42451, 42497,\n",
       "         42514, 42502, 42531, 41078, 42556, 42515, 40045, 42459, 42452, 42497,\n",
       "         40188, 41599, 42465,     3]),\n",
       " tensor([41532, 42488, 42453, 42351, 42451, 42455, 42404, 42502, 42541, 42555,\n",
       "         42445, 42515, 40045, 42507, 42432, 42495, 42500, 42435, 42416, 42463,\n",
       "         42516, 42468, 42531, 42541, 42499, 41271, 42497, 42484, 42481, 42455,\n",
       "         42360, 42476, 42465,     3]),\n",
       " tensor([42516, 42453, 42518, 42451, 42519, 42396, 42455, 42517, 42481, 42424,\n",
       "         42515, 40045, 42451, 42466,    80, 42451, 42469, 42459, 42407, 42445,\n",
       "         42396, 42452, 42455, 41566, 42299, 42502, 42436, 42451, 42474, 42424,\n",
       "         42515, 40045, 42499, 42454, 42465, 42488, 42451, 42472, 42445, 42469,\n",
       "         42242, 42451, 42463, 42077, 42445, 42393, 41690, 42489, 42386, 42188,\n",
       "         42465,     3]),\n",
       " tensor([42465, 42501, 42502, 42455, 42404, 42502, 38680, 42475, 42451, 42500,\n",
       "         42535, 42446, 42463, 42263, 42451, 42485, 42452, 42477, 42366, 42502,\n",
       "         42102, 42505, 42475, 42451, 42323, 42442, 42475, 42463, 42494, 42453,\n",
       "         42492, 41231, 42465,     3]),\n",
       " tensor([35132, 42468, 42497,    80, 42519, 42462, 42455, 42349, 42463, 42455,\n",
       "         42536, 42442, 42481, 42455, 40505, 42306, 42502, 41949, 42499, 42389,\n",
       "         42492, 42505, 42514, 42480, 42451, 42485, 42452, 42497, 42117, 42237,\n",
       "         42451, 42445, 42380, 42394, 42555, 42451, 42485, 42452, 42497,   133,\n",
       "         42448, 42486, 42451, 42463, 42444, 42496, 42455, 42476, 42468, 42244,\n",
       "         40736, 42465,     3])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42485, 35732, 42367, 42450, 38674,    10, 42508, 42313, 42472, 38387,\n",
       "         42474, 42459, 42455, 42471, 42228, 42500, 42356, 42451, 42463, 42441,\n",
       "         42463, 42416, 42306, 42468, 42437, 42396, 42445, 42526, 42450, 42105,\n",
       "         42115, 42451, 42550, 42366, 42465,     3,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [42007, 42500, 42497, 42204, 42502, 42035, 42438, 42453, 42451, 42497,\n",
       "         42514, 42502, 42531, 41078, 42556, 42515, 40045, 42459, 42452, 42497,\n",
       "         40188, 41599, 42465,     3,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [41532, 42488, 42453, 42351, 42451, 42455, 42404, 42502, 42541, 42555,\n",
       "         42445, 42515, 40045, 42507, 42432, 42495, 42500, 42435, 42416, 42463,\n",
       "         42516, 42468, 42531, 42541, 42499, 41271, 42497, 42484, 42481, 42455,\n",
       "         42360, 42476, 42465,     3,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [42516, 42453, 42518, 42451, 42519, 42396, 42455, 42517, 42481, 42424,\n",
       "         42515, 40045, 42451, 42466,    80, 42451, 42469, 42459, 42407, 42445,\n",
       "         42396, 42452, 42455, 41566, 42299, 42502, 42436, 42451, 42474, 42424,\n",
       "         42515, 40045, 42499, 42454, 42465, 42488, 42451, 42472, 42445, 42469,\n",
       "         42242, 42451, 42463, 42077, 42445, 42393, 41690, 42489, 42386, 42188,\n",
       "         42465,     3,     0],\n",
       "        [42465, 42501, 42502, 42455, 42404, 42502, 38680, 42475, 42451, 42500,\n",
       "         42535, 42446, 42463, 42263, 42451, 42485, 42452, 42477, 42366, 42502,\n",
       "         42102, 42505, 42475, 42451, 42323, 42442, 42475, 42463, 42494, 42453,\n",
       "         42492, 41231, 42465,     3,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [35132, 42468, 42497,    80, 42519, 42462, 42455, 42349, 42463, 42455,\n",
       "         42536, 42442, 42481, 42455, 40505, 42306, 42502, 41949, 42499, 42389,\n",
       "         42492, 42505, 42514, 42480, 42451, 42485, 42452, 42497, 42117, 42237,\n",
       "         42451, 42445, 42380, 42394, 42555, 42451, 42485, 42452, 42497,   133,\n",
       "         42448, 42486, 42451, 42463, 42444, 42496, 42455, 42476, 42468, 42244,\n",
       "         40736, 42465,     3]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad = pad_sequence(sequence, batch_first=True)\n",
    "pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 53])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset = dataset, batch_size = 2, collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "venv_Abrstract_Labeling",
   "language": "python",
   "name": "venv_abrstract_labeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
