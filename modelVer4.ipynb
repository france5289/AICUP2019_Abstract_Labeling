{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tokenizer import NLTKTokenizer\n",
    "\n",
    "CWD = os.getcwd()\n",
    "TRAIN_DATA_PATH = os.path.join(CWD, 'data', 'trainset.csv')\n",
    "VALID_DATA_PATH = os.path.join(CWD, 'data', 'validset.csv')\n",
    "TEST_DATA_PATH = os.path.join(CWD, 'data', 'testset.csv')\n",
    "DICT_PATH = os.path.join(CWD, 'data', 'dictionary.pkl')\n",
    "WORKERS = os.cpu_count() // 2\n",
    "Tokenizer = NLTKTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenDict(train, valid):\n",
    "    global Tokenizer\n",
    "    if os.path.exists(DICT_PATH):\n",
    "        Tokenizer = NLTKTokenizer.load_from_file(DICT_PATH)\n",
    "    else:\n",
    "        for item in tqdm(train['Abstract'], desc='Train set'):\n",
    "            Tokenizer.build_dict([item])\n",
    "\n",
    "        for item in tqdm(valid['Abstract'], desc='Valid set'):\n",
    "            Tokenizer.build_dict([item])\n",
    "        Tokenizer.save_to_file(DICT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def labels_to_onehot(labels):\n",
    "    '''\n",
    "    Convert labels to one-hot encoding\n",
    "\n",
    "    Args : \n",
    "        labels:( DataFrame column item ) \n",
    "    Return :\n",
    "        one_hot_labels: ( DataFrame column item )\n",
    "    '''\n",
    "    one_hot_labels = []\n",
    "    label_list = labels.split(' ')\n",
    "    label_dict = {\n",
    "        'BACKGROUND': 0,\n",
    "        'OBJECTIVES': 1,\n",
    "        'METHODS': 2,\n",
    "        'RESULTS': 3,\n",
    "        'CONCLUSIONS': 4,\n",
    "        'OTHERS': 5\n",
    "    }\n",
    "    for label in label_list:\n",
    "        onehot = [0, 0, 0, 0, 0, 0]\n",
    "        for l in label.split('/'):\n",
    "            onehot[label_dict[l]] = 1\n",
    "        one_hot_labels.append(onehot)\n",
    "\n",
    "    return one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(dataset):\n",
    "    '''\n",
    "    encode 'Abstract' and convert label to one_hot\n",
    "\n",
    "    Args:\n",
    "        dataset(pd.DataFrame)\n",
    "    '''\n",
    "    global Tokenizer\n",
    "    tqdm.pandas()\n",
    "    dataset['Abstract'] = dataset['Abstract'].progress_apply(func=Tokenizer.encode)\n",
    "    if 'Task 1' in dataset.columns:\n",
    "        dataset['Task 1'] = dataset['Task 1'].progress_apply(func=labels_to_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Generate relative dictionary\n"
    }
   ],
   "source": [
    "train = pd.read_csv(TRAIN_DATA_PATH)\n",
    "valid = pd.read_csv(VALID_DATA_PATH)\n",
    "test = pd.read_csv(TEST_DATA_PATH)\n",
    "print('Generate relative dictionary')\n",
    "GenDict(train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 42180/42180 [00:05<00:00, 7182.60it/s]\n100%|██████████| 42180/42180 [00:00<00:00, 257688.07it/s]\n"
    }
   ],
   "source": [
    "encode_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Abstract</th>\n      <th>Task 1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1...</td>\n      <td>[[0, 1, 0, 0, 0, 0]]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[23, 13, 24, 25, 26, 27, 28, 20, 29, 30, 31, ...</td>\n      <td>[[1, 0, 0, 0, 0, 0]]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 6, 1...</td>\n      <td>[[0, 0, 0, 0, 0, 1]]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[50, 51, 11, 52, 53, 19, 20, 54, 55, 6, 11, 5...</td>\n      <td>[[0, 0, 0, 0, 0, 1]]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[68, 69, 25, 70, 71, 72, 56, 73, 74, 75, 20, ...</td>\n      <td>[[0, 0, 0, 1, 0, 0]]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>42175</th>\n      <td>[[40322, 6100, 391, 18299, 6, 15515, 6, 15939,...</td>\n      <td>[[1, 0, 0, 0, 0, 0]]</td>\n    </tr>\n    <tr>\n      <th>42176</th>\n      <td>[[68, 470, 547, 548, 1728, 2806, 6539, 19246, ...</td>\n      <td>[[0, 0, 1, 1, 0, 0]]</td>\n    </tr>\n    <tr>\n      <th>42177</th>\n      <td>[[90, 209, 5436, 25, 1725, 3482, 1456, 131, 79...</td>\n      <td>[[0, 0, 0, 0, 1, 0]]</td>\n    </tr>\n    <tr>\n      <th>42178</th>\n      <td>[[198, 865, 6, 96, 4261, 11, 3804, 6, 56, 2706...</td>\n      <td>[[1, 0, 0, 0, 0, 0]]</td>\n    </tr>\n    <tr>\n      <th>42179</th>\n      <td>[[17125, 2693, 1800, 1987, 56, 1618, 76, 286, ...</td>\n      <td>[[1, 0, 0, 0, 0, 0]]</td>\n    </tr>\n  </tbody>\n</table>\n<p>42180 rows × 2 columns</p>\n</div>",
      "text/plain": "                                                Abstract                Task 1\n0      [[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1...  [[0, 1, 0, 0, 0, 0]]\n1      [[23, 13, 24, 25, 26, 27, 28, 20, 29, 30, 31, ...  [[1, 0, 0, 0, 0, 0]]\n2      [[34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 6, 1...  [[0, 0, 0, 0, 0, 1]]\n3      [[50, 51, 11, 52, 53, 19, 20, 54, 55, 6, 11, 5...  [[0, 0, 0, 0, 0, 1]]\n4      [[68, 69, 25, 70, 71, 72, 56, 73, 74, 75, 20, ...  [[0, 0, 0, 1, 0, 0]]\n...                                                  ...                   ...\n42175  [[40322, 6100, 391, 18299, 6, 15515, 6, 15939,...  [[1, 0, 0, 0, 0, 0]]\n42176  [[68, 470, 547, 548, 1728, 2806, 6539, 19246, ...  [[0, 0, 1, 1, 0, 0]]\n42177  [[90, 209, 5436, 25, 1725, 3482, 1456, 131, 79...  [[0, 0, 0, 0, 1, 0]]\n42178  [[198, 865, 6, 96, 4261, 11, 3804, 6, 56, 2706...  [[1, 0, 0, 0, 0, 0]]\n42179  [[17125, 2693, 1800, 1987, 56, 1618, 76, 286, ...  [[1, 0, 0, 0, 0, 0]]\n\n[42180 rows x 2 columns]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Abstract(Dataset):\n",
    "    def __init__(self, data, pad_idx, eos_id):\n",
    "        self.data = data\n",
    "        self.pad_idx = pad_idx\n",
    "        self.eos_token = eos_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data.iloc[index]\n",
    "\n",
    "    def collate_fn(self, datas):\n",
    "        '''\n",
    "        Args:\n",
    "            datas : a list of dataframe row(pd.Series)\n",
    "        '''\n",
    "        abstracts = [ torch.as_tensor(sent, dtype=torch.long) for data in datas for sent in data['Abstract'] ]\n",
    "        batch_abstracts = pad_sequence(abstracts, batch_first=True, padding_value=self.pad_idx)\n",
    "\n",
    "        _, s = batch_abstracts.size()  # b: batch, s:sequence length\n",
    "        batch_eos = batch_abstracts == self.eos_token\n",
    "        eos_index_matrix = batch_eos.nonzero()\n",
    "        eos_index_list = list()\n",
    "        prev = 0\n",
    "        for row in eos_index_matrix:\n",
    "            eos_index_list.append(row[1].item() + prev)\n",
    "            prev = prev + s\n",
    "\n",
    "        batch_labels = None\n",
    "        labels = [ label for data in datas if 'Task 1' in data for label in data['Task 1'] ]\n",
    "        if len(labels) != 0:\n",
    "            batch_labels = torch.as_tensor(labels, dtype=torch.float)\n",
    "            batch_labels = batch_labels.view(-1, 6)\n",
    "\n",
    "        return batch_abstracts, batch_labels, torch.as_tensor(eos_index_list, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Abstract(train, 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Abstract    [[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1...\nTask 1                                   [[0, 1, 0, 0, 0, 0]]\nName: 0, dtype: object"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset=trainset, batch_size=2, shuffle=True, collate_fn=trainset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[22622,    42,   470,   108,    16, 22623,    20,   730,    19,    20,\n            76,    22,     3,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0],\n        [ 5927,   122,   192,  1743,    25,  6120, 17705,    20,  1003,   764,\n           191,    96,   712,  1569,    96,   501,  2128,    96,   825,  1309,\n           305,  1258,    22,     3]])\ntensor([[0., 0., 1., 0., 0., 0.],\n        [1., 1., 0., 0., 0., 0.]])\ntensor([12, 47])\n"
    }
   ],
   "source": [
    "for x, y, z in trainloader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(z)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "venv_Abrstract_Labeling",
   "language": "python",
   "name": "venv_abrstract_labeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}