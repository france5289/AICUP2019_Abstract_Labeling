{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/dean/.cache/torch/hub/huggingface_pytorch-pretrained-BERT_master\n"
     ]
    }
   ],
   "source": [
    "GITHUB_REPO = \"huggingface/pytorch-pretrained-BERT\" # from Huggingface\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-uncased\"\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = torch.hub.load(GITHUB_REPO, 'tokenizer', PRETRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = os.getcwd()\n",
    "if 'task1' not in CWD:\n",
    "    CWD = os.path.join(CWD, 'task1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join('data/task1_trainset.csv'), dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Created Date</th>\n",
       "      <th>Task 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D00001</td>\n",
       "      <td>A Brain-Inspired Trust Management Model to Ass...</td>\n",
       "      <td>Rapid popularity of Internet of Things (IoT) a...</td>\n",
       "      <td>Mahmud/Kaiser/Rahman/Rahman/Shabut/Al-Mamun/Hu...</td>\n",
       "      <td>cs.CR/cs.AI/q-bio.NC</td>\n",
       "      <td>2018-01-11</td>\n",
       "      <td>BACKGROUND OBJECTIVES METHODS METHODS RESULTS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D00002</td>\n",
       "      <td>On Efficient Computation of Shortest Dubins Pa...</td>\n",
       "      <td>In this paper, we address the problem of compu...</td>\n",
       "      <td>Sadeghi/Smith</td>\n",
       "      <td>cs.SY/cs.RO/math.OC</td>\n",
       "      <td>2016-09-21</td>\n",
       "      <td>OBJECTIVES OTHERS METHODS/RESULTS RESULTS RESULTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D00003</td>\n",
       "      <td>Data-driven Upsampling of Point Clouds</td>\n",
       "      <td>High quality upsampling of sparse 3D point clo...</td>\n",
       "      <td>Zhang/Jiang/Yang/Yamakawa/Shimada/Kara</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>2018-07-07</td>\n",
       "      <td>BACKGROUND OBJECTIVES METHODS METHODS METHODS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D00004</td>\n",
       "      <td>Accessibility or Usability of InteractSE? A He...</td>\n",
       "      <td>Internet is the main source of information now...</td>\n",
       "      <td>Aqle/Khowaja/Al-Thani</td>\n",
       "      <td>cs.HC</td>\n",
       "      <td>2018-08-29</td>\n",
       "      <td>BACKGROUND BACKGROUND BACKGROUND OBJECTIVES OB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D00005</td>\n",
       "      <td>Spatio-Temporal Facial Expression Recognition ...</td>\n",
       "      <td>Automated Facial Expression Recognition (FER) ...</td>\n",
       "      <td>Hasani/Mahoor</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>BACKGROUND BACKGROUND BACKGROUND BACKGROUND ME...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                              Title  \\\n",
       "0  D00001  A Brain-Inspired Trust Management Model to Ass...   \n",
       "1  D00002  On Efficient Computation of Shortest Dubins Pa...   \n",
       "2  D00003             Data-driven Upsampling of Point Clouds   \n",
       "3  D00004  Accessibility or Usability of InteractSE? A He...   \n",
       "4  D00005  Spatio-Temporal Facial Expression Recognition ...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Rapid popularity of Internet of Things (IoT) a...   \n",
       "1  In this paper, we address the problem of compu...   \n",
       "2  High quality upsampling of sparse 3D point clo...   \n",
       "3  Internet is the main source of information now...   \n",
       "4  Automated Facial Expression Recognition (FER) ...   \n",
       "\n",
       "                                             Authors            Categories  \\\n",
       "0  Mahmud/Kaiser/Rahman/Rahman/Shabut/Al-Mamun/Hu...  cs.CR/cs.AI/q-bio.NC   \n",
       "1                                      Sadeghi/Smith   cs.SY/cs.RO/math.OC   \n",
       "2             Zhang/Jiang/Yang/Yamakawa/Shimada/Kara                 cs.CV   \n",
       "3                              Aqle/Khowaja/Al-Thani                 cs.HC   \n",
       "4                                      Hasani/Mahoor                 cs.CV   \n",
       "\n",
       "  Created Date                                             Task 1  \n",
       "0   2018-01-11  BACKGROUND OBJECTIVES METHODS METHODS RESULTS ...  \n",
       "1   2016-09-21  OBJECTIVES OTHERS METHODS/RESULTS RESULTS RESULTS  \n",
       "2   2018-07-07  BACKGROUND OBJECTIVES METHODS METHODS METHODS ...  \n",
       "3   2018-08-29  BACKGROUND BACKGROUND BACKGROUND OBJECTIVES OB...  \n",
       "4   2017-03-20  BACKGROUND BACKGROUND BACKGROUND BACKGROUND ME...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove (current) redundant columns.\n",
    "df_train.drop('Id',axis=1,inplace=True)\n",
    "df_train.drop('Title',axis=1,inplace=True)\n",
    "df_train.drop('Categories',axis=1,inplace=True)\n",
    "df_train.drop('Created Date',axis=1, inplace=True)\n",
    "df_train.drop('Authors',axis=1,inplace=True)\n",
    "#df_train['Abstract'] = df_train['Abstract'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validset = train_test_split(df_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_onehot(raw_labels):\n",
    "    \"\"\" Convert label to onehot .\n",
    "        Args:\n",
    "            labels (string): sentence's labels.\n",
    "        Return:\n",
    "            outputs (onehot list): sentence's onehot label.\n",
    "    \"\"\"\n",
    "    label_dict = {'BACKGROUND': 0, 'OBJECTIVES':1, 'METHODS':2, 'RESULTS':3, 'CONCLUSIONS':4, 'OTHERS':5}\n",
    "    label_onehot = [0,0,0,0,0,0]\n",
    "    for l in raw_labels.split('/'):\n",
    "        label_onehot[label_dict[l]] = 1\n",
    "    return label_onehot\n",
    "\n",
    "\n",
    "def convert_to_bert_indices(sentence):\n",
    "    word_pieces = [\"[CLS]\"]\n",
    "    tokenized_sent = tokenizer.tokenize(sentence)\n",
    "    word_pieces = word_pieces + tokenized_sent\n",
    "    word_pieces = word_pieces + [\"[SEP]\"]\n",
    "\n",
    "    word_pieces_ids = tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "    word_pieces_mask = [0]*len(word_pieces_ids)\n",
    "    if len(word_pieces_ids) != len(word_pieces_mask):\n",
    "        print(\"Fuck\")\n",
    "    return (word_pieces_ids, word_pieces_mask)\n",
    "\n",
    "\n",
    "def preprocess_sample(data):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data (dict)\n",
    "    Returns:\n",
    "        dict\n",
    "    \"\"\"\n",
    "    processed = {}\n",
    "    \n",
    "    ## clean abstracts by removing $$$    \n",
    "    processed['Abstract'] = [convert_to_bert_indices(sent) for sent in data['Abstract'].split('$$$')]\n",
    "    \n",
    "    ## convert the labels into one-hot encoding\n",
    "    if 'Task 1' in data:\n",
    "        processed['Label'] = [label_to_onehot(label) for label in data['Task 1'].split(' ')]\n",
    "        \n",
    "    return processed\n",
    "\n",
    "\n",
    "def preprocess_samples(dataset):\n",
    "    \"\"\" Worker function.\n",
    "\n",
    "    Args:\n",
    "        dataset (list of dict)\n",
    "    Returns:\n",
    "        list of processed dict.\n",
    "    \"\"\"\n",
    "    processed = []\n",
    "    for sample in dataset.iterrows():\n",
    "        processed.append(preprocess_sample(sample[1]))\n",
    "\n",
    "    return processed\n",
    "\n",
    "\n",
    "def get_dataset(raw_dataset):\n",
    "    \"\"\" Load data and return dataset for training and validating.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Path to the data.\n",
    "    \"\"\"\n",
    "    processed = preprocess_samples(raw_dataset)\n",
    "    \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Start processing trainset...\n",
      "[INFO] Start processing validset...\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] Start processing trainset...')\n",
    "train = get_dataset(trainset)\n",
    "print('[INFO] Start processing validset...')\n",
    "valid = get_dataset(validset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = AbstractDataset(train)\n",
    "validData = AbstractDataset(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence    \n",
    "\n",
    "def create_mini_batch(samples):\n",
    "    max_sent = max([len(sample['Abstract']) for sample in samples]) # 文章最多有幾句\n",
    "    #print(max_sent)\n",
    "    max_len = max([len(sentence[0]) for sample in samples for sentence in sample['Abstract']]) # 單句最長的長度\n",
    "    \n",
    "    batch_abstract = []\n",
    "    batch_segment = []\n",
    "    batch_label = []\n",
    "    sent_len = []\n",
    "    \n",
    "    for sample in samples:\n",
    "        sample_sent_num = len(sample['Abstract'])\n",
    "        pad_abstract = []\n",
    "        pad_segment = []\n",
    "        \n",
    "        for sentence, segment in sample['Abstract']:\n",
    "            if len(sentence) >= max_len:\n",
    "                pad_abstract.append(sentence[:max_len])\n",
    "                pad_segment.append(segment[:max_len])\n",
    "            else:\n",
    "                pad_abstract.append( sentence +  [0] * (max_len - len(sentence)) )\n",
    "                pad_segment.append( segment + [0] * (max_len - len(segment)) )\n",
    "                \n",
    "        sent_len.append(len(pad_abstract))\n",
    "        #print('pad_abstract:', len(pad_abstract))\n",
    "        #print('sample_sent_num:', sample_sent_num)\n",
    "        #print('pad_segment:', len(pad_segment))\n",
    "        \n",
    "        pad_abstract.extend([ [101] + [102] + [0] * (max_len -2) ]* (max_sent - sample_sent_num))\n",
    "        #pad_abstract.extend([[0]*max_len]*(max_sent - len(pad_abstract)))\n",
    "        pad_segment.extend([[0]*max_len]*(max_sent - len(pad_segment)))\n",
    "        #print('pad_abstract2:', len(pad_abstract))\n",
    "        #print('pad_segment2:', len(pad_segment))\n",
    "        batch_abstract.append(pad_abstract)  \n",
    "        batch_segment.append(pad_segment)\n",
    "        \n",
    "        # gather labels\n",
    "        if 'Label' in sample:\n",
    "            pad_label = sample['Label']\n",
    "            pad_label.extend([[0]*6]*(max_sent-len(pad_label)))\n",
    "            batch_label.append(pad_label)\n",
    "            \n",
    "    batch_abstract = torch.LongTensor(batch_abstract)\n",
    "    #batch_abstract = pad_sequence(batch_abstract, batch_first=True)     \n",
    "    batch_segment = torch.LongTensor(batch_segment)\n",
    "    #batch_segment = pad_sequence(batch_segment, batch_first=True)\n",
    "    batch_label = torch.FloatTensor(batch_label)\n",
    "    #print('pad_abstract:', len(pad_abstract))\n",
    "    #print('sent_len:', len(sent_len))\n",
    "    \n",
    "    # attention\n",
    "    masks_tensors = torch.zeros(batch_abstract.shape)\n",
    "    masks_tensors = masks_tensors.masked_fill(batch_abstract != 0, 1)\n",
    "    #print('batch_label:', batch_label)\n",
    "    #print('batch_label_size:', batch_label.shape)\n",
    "        \n",
    "    return batch_abstract, batch_segment, masks_tensors, batch_label, sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "NUM_LABELS = 6\n",
    "learning_rate = 2e-5\n",
    "path_name = 'bert'\n",
    "max_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"finetuning_task\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"num_labels\": 2,\n",
       "  \"output_attentions\": false,\n",
       "  \"output_hidden_states\": false,\n",
       "  \"output_past\": true,\n",
       "  \"pruned_heads\": {},\n",
       "  \"torchscript\": false,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_bfloat16\": false,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from transformers import BertTokenizer, BertModel, BertConfig, BertPreTrainedModel\n",
    "#BertConfig.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class BertForSequenceClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertForSequenceClassification, self).__init__(config)\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.bert = BertModel(config)  # load pre-trained BERT\n",
    "        #self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        # add a linear layer\n",
    "        self.classifier = nn.Linear(config.hidden_size, 6)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None, position_ids=None):\n",
    "        b, s, w = input_ids.shape\n",
    "        input_ids = input_ids.view(b*s, w)\n",
    "        attention_mask = attention_mask.view(b*s, w)\n",
    "        token_type_ids = token_type_ids.view(b*s, w)\n",
    "\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "        sequence_outputs = outputs[0]\n",
    "        #pooled_output = self.dropout(outputs)\n",
    "        logits = self.sigmoid(self.classifier(sequence_outputs))\n",
    "        #print(logits[0].shape)\n",
    "\n",
    "        return logits\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForSequenceClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertForSequenceClassification, self).__init__(config)\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.hidden_dim = 512\n",
    "        self.bert = BertModel(config)  # load pre-trained BERT\n",
    "        #self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        # add a linear layer\n",
    "        #self.sent_rnn = nn.GRU(config.hidden_size,\n",
    "        #                       self.hidden_dim,\n",
    "        #                       num_layers=1,\n",
    "        #                       bidirectional=True,\n",
    "        #                       batch_first=True)\n",
    "        self.l1 = nn.Linear(self.hidden_size, self.hidden_dim)\n",
    "        self.classifier = nn.Linear(self.hidden_dim, 6)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None, position_ids=None):\n",
    "        b, s, w = input_ids.shape\n",
    "        input_ids = input_ids.view(b*s, w)\n",
    "        attention_mask = attention_mask.view(b*s, w)\n",
    "        token_type_ids = token_type_ids.view(b*s, w)\n",
    "\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output = torch.mean(sequence_output, dim=1)\n",
    "        #sequence_output = sequence_output.view(b, s, self.hidden_size)\n",
    "        #sequence_output, _ = self.sent_rnn(sequence_output)\n",
    "        sequence_output = sequence_output.view(b, s, self.hidden_size)\n",
    "        x = torch.relu(self.l1(sequence_output))\n",
    "        #pooled_output = self.dropout(outputs)\n",
    "        logits = self.sigmoid(self.classifier(x))\n",
    "        #print(logits[0].shape)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper functions for scoring\n",
    "\n",
    "class F1():\n",
    "    def __init__(self):\n",
    "        self.threshold = 0.5\n",
    "        self.n_precision = 0\n",
    "        self.n_recall = 0\n",
    "        self.n_corrects = 0\n",
    "        self.name = 'F1'\n",
    "\n",
    "    def reset(self):\n",
    "        self.n_precision = 0\n",
    "        self.n_recall = 0\n",
    "        self.n_corrects = 0\n",
    "\n",
    "    def update(self, predicts, groundTruth):\n",
    "        predicts = predicts > self.threshold\n",
    "        self.n_precision += torch.sum(predicts).data.item()\n",
    "        self.n_recall += torch.sum(groundTruth).data.item()\n",
    "        self.n_corrects += torch.sum(groundTruth.type(torch.bool) * predicts).data.item()\n",
    "\n",
    "    def get_score(self):\n",
    "        recall = self.n_corrects / self.n_recall\n",
    "        precision = self.n_corrects / (self.n_precision + 1e-20)\n",
    "        return 2 * (recall * precision) / (recall + precision + 1e-20)\n",
    "\n",
    "    def print_score(self):\n",
    "        score = self.get_score()\n",
    "        return '{:.5f}'.format(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_epoch(epoch, mode):\n",
    "    model.train(True)\n",
    "    if mode==\"train\":\n",
    "        description = 'Train'\n",
    "        dataset = trainData\n",
    "        shuffle = True\n",
    "    else:\n",
    "        description = 'Valid'\n",
    "        dataset = validData\n",
    "        shuffle = False\n",
    "    dataloader = DataLoader(dataset=dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            collate_fn=create_mini_batch,\n",
    "                            num_workers=8)\n",
    "\n",
    "    trange = tqdm(enumerate(dataloader), total=len(dataloader), desc=description)\n",
    "    loss = 0\n",
    "    f1_score = F1()\n",
    "    for i, (token_tensors, segments_tensors, masks_tensors, label_ids, sent_len) in trange:\n",
    "        o_labels, batch_losses = _run_iter(token_tensors, segments_tensors, masks_tensors, label_ids, sent_len)\n",
    "        _loss = 0\n",
    "        if mode==\"train\":\n",
    "            opt.zero_grad()\n",
    "            for k, batch_loss in enumerate(batch_losses):\n",
    "                batch_loss.backward(retain_graph=True)\n",
    "                _loss += batch_loss.item()\n",
    "            opt.step()\n",
    "        else:\n",
    "            for k, batch_loss in enumerate(batch_losses):\n",
    "                _loss += batch_loss.item()\n",
    "\n",
    "        #loss += batch_loss.item()\n",
    "        loss += _loss\n",
    "        #if i%500==0:\n",
    "        #    print(o_labels)\n",
    "            \n",
    "        for j, dl in enumerate(o_labels):\n",
    "            #print('sent_len', len(sent_len))\n",
    "            #print(j)\n",
    "        #    #print('label_ids:', label_ids[j][:sent_len[j]])\n",
    "        #    #print('dl:', dl[:sent_len[j]])\n",
    "            f1_score.update(dl[:sent_len[j]].cpu(), label_ids[j][:sent_len[j]])\n",
    "        #f1_score.update(o_labels, label_ids)\n",
    "            \n",
    "        trange.set_postfix(loss=loss / (i + 1), f1=f1_score.print_score())\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    if mode==\"train\":\n",
    "        history['train'].append({'f1':f1_score.get_score(), 'loss':loss/ len(trange)})\n",
    "        writer.add_scalar('Loss/train', loss/ len(trange), epoch)\n",
    "        writer.add_scalar('F1_score/train', f1_score.get_score(), epoch)\n",
    "    else:\n",
    "        history['valid'].append({'f1':f1_score.get_score(), 'loss':loss/ len(trange)})\n",
    "        writer.add_scalar('Loss/valid', loss/ len(trange), epoch)\n",
    "        writer.add_scalar('F1_score/valid', f1_score.get_score(), epoch)\n",
    "    trange.close()\n",
    "    \n",
    "\n",
    "def _run_iter(tokens_tensors, segments_tensors ,masks_tensors, label_ids, sent_len):\n",
    "    tokens_tensors = tokens_tensors.to(device)\n",
    "    segments_tensors = segments_tensors.to(device)\n",
    "    masks_tensors = masks_tensors.to(device)\n",
    "    \n",
    "    o_labels = model(input_ids=tokens_tensors, token_type_ids=segments_tensors, attention_mask=masks_tensors)\n",
    "    l_losses = []\n",
    "    for i, sent in enumerate(sent_len):\n",
    "        l_loss = criteria(o_labels[i][:sent_len[i]].cpu(), label_ids[i][:sent_len[i]])\n",
    "        l_losses.append(l_loss)\n",
    "    \n",
    "    return o_labels, l_losses\n",
    "\n",
    "def save(epoch, path_name):\n",
    "    if not os.path.exists(os.path.join(CWD, 'model', path_name)):\n",
    "        os.makedirs(os.path.join(CWD, 'model', path_name))\n",
    "    path = os.path.join(CWD, 'model', path_name)\n",
    "    torch.save(model.state_dict(), os.path.join(path, 'model.pkl.'+str(epoch) ))\n",
    "    with open( os.path.join( path, 'history.json'), 'w') as f:\n",
    "        json.dump(history, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a526b302ce23408385f78534d1eac756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train', max=3150, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 42.00 MiB (GPU 0; 7.93 GiB total capacity; 6.85 GiB already allocated; 17.62 MiB free; 521.40 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-bfc1c907c722>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bert'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-3bda89eeef9b>\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(epoch, mode)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mf1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegments_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_len\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mo_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegments_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0m_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-3bda89eeef9b>\u001b[0m in \u001b[0;36m_run_iter\u001b[0;34m(tokens_tensors, segments_tensors, masks_tensors, label_ids, sent_len)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mmasks_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mo_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegments_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasks_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0ml_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-43491b173b81>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, labels, position_ids)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    625\u001b[0m         encoder_outputs = self.encoder(embedding_output,\n\u001b[1;32m    626\u001b[0m                                        \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                        head_mask=head_mask)\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mattention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mgelu\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mAlso\u001b[0m \u001b[0msee\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1606.08415\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgelu_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 42.00 MiB (GPU 0; 7.93 GiB total capacity; 6.85 GiB already allocated; 17.62 MiB free; 521.40 MiB cached)"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification(BertConfig.from_pretrained('bert-base-uncased'))\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criteria = torch.nn.BCELoss()\n",
    "model.to(device)\n",
    "history = {'train':[],'valid':[]}\n",
    "\n",
    "## Tensorboard\n",
    "## save path: test_experiment/\n",
    "tf_path = os.path.join(CWD, 'model', path_name)\n",
    "if not os.path.exists(tf_path):\n",
    "    os.mkdir(tf_path)\n",
    "writer = SummaryWriter(tf_path)\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    _run_epoch(epoch, 'train')\n",
    "    _run_epoch(epoch, 'valid')\n",
    "    save(epoch, 'bert')\n",
    "\n",
    "# Plot the training results \n",
    "with open(os.path.join(CWD,'model/bert/history.json'), 'r') as f:\n",
    "    history = json.loads(f.read())\n",
    "    \n",
    "train_loss = [l['loss'] for l in history['train']]\n",
    "valid_loss = [l['loss'] for l in history['valid']]\n",
    "train_f1 = [l['f1'] for l in history['train']]\n",
    "valid_f1 = [l['f1'] for l in history['valid']]\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title('Loss')\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(valid_loss, label='valid')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title('F1 Score')\n",
    "plt.plot(train_f1, label='train')\n",
    "plt.plot(valid_f1, label='valid')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Best F1 score ', max([[l['f1'], idx] for idx, l in enumerate(history['valid'])]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
